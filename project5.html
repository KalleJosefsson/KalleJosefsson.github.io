<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5: Diffusion Models</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 50px;
        }
        h1 {
            font-size: 2.5em;
            color: #4CAF50;
        }
        h2, h3 {
            color: #4CAF50;
            margin-top: 40px;
        }
        p {
            font-size: 1.2em;
            line-height: 1.6em;
        }
        .image-row {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .image-container {
            text-align: center;
        }
        .image-container img {
            height: 200px; /* Set fixed height for all images */
            width: auto; /* Automatically adjust width to keep aspect ratio */
            border-radius: 10px;
        }
        .caption {
            margin-top: 10px;
            font-size: 14px;
            font-style: italic;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            font-size: 0.8em;
            color: #777;
        }
    </style>
</head>
<body>
    <header>
        <h1>Project 5: Diffusion Models</h1>
    </header>

    <h2>Part 0. Setup</h2>
    <p>
        For this part, we set up the diffusion model with a random seed (185). This seed will be used throughout the project. In part A, we work with images of size 64x64 pixels, which might not be as sharp. In part B, the images improve significantly. Below, we show results with different inference steps.
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part1_1_n20.png" alt="20 Denoising Steps">
            <div class="caption">20 Denoising Steps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_1_n50.png" alt="50 Denoising Steps">
            <div class="caption">50 Denoising Steps</div>
        </div>
    </div>

    <h2>Part 1. Implementing the Forward Process</h2>
    <p>
        Adding noise progressively to an image is key in the diffusion process. This allows the model to learn how to reverse noise, recovering the clean image. Below are examples of the test image at various noise levels:
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part1_1_noise.png" alt="Image with 250 timesteps">
            <div class="caption">250 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_1_noise500.png" alt="Image with 500 timesteps">
            <div class="caption">500 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_1_noise750.png" alt="Image with 750 timesteps">
            <div class="caption">750 timesteps</div>
        </div>
    </div>

    <h2>Part 2. Denoising Using Classical Gaussian Blurring</h2>
    <p>
        Gaussian blurring was used to denoise the images. This method is not effective, as seen below:
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part1_2_250.png" alt="Blurred image at 250 timesteps">
            <div class="caption">250 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_2_500.png" alt="Blurred image at 500 timesteps">
            <div class="caption">500 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_2_750.png" alt="Blurred image at 750 timesteps">
            <div class="caption">750 timesteps</div>
        </div>
    </div>

    <h2>Part 3. One-Step Denoising Using the Diffusion Model</h2>
    <p>
        A U-Net estimates and removes Gaussian noise. The model considers the timestep as an input parameter, making it easier to determine the amount of noise to remove:
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part1_3_250.png" alt="Denoised image at 250 timesteps">
            <div class="caption">250 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_3_500.png" alt="Denoised image at 500 timesteps">
            <div class="caption">500 timesteps</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_3_750.png" alt="Denoised image at 750 timesteps">
            <div class="caption">750 timesteps</div>
        </div>
    </div>

    <h2>Part 4. Iterative Denoising Using the Diffusion Model</h2>
    <p>
        Iterative denoising works better than classical methods. To speed up the process, denoising is performed every 30 timesteps. Below is the progression of denoising and the final comparison to classical methods:
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part1_4_690.png" alt="Denoising begins">
            <div class="caption">Beginning of denoising</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_4_390.png" alt="Midway through denoising">
            <div class="caption">Middle of denoising</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_4_90.png" alt="Denoising completed">
            <div class="caption">End of denoising</div>
        </div>
    </div>
    <div class="image-container">
        <img src="images5/part1_4_finals.png" alt="Final comparison to classical methods">
        <div class="caption">Final comparison with classical denoising</div>
    </div>

        <h2>Part 5. Diffusion model sampling</h2>
    <p>
        In this part, we used the trained diffusion model to generate five random images. These images were sampled starting from pure noise and progressively denoised to create realistic outputs. This demonstrates the model's ability to synthesize diverse images based on the learned data distribution.
    </p>
    <div class="image-container">
        <img src="images5/part1_5.png" alt="Five Randomly Generated Images">
        <div class="caption">Five randomly generated images using the diffusion model</div>
    </div>
    <h2>Part 6. Classifier-Free Guidance (CFG)</h2>
    <p>
        To improve the quality of generated images, we implemented Classifier-Free Guidance (CFG). This technique combines a conditional noise estimate based on a text prompt with an unconditional noise estimate, weighted by a guidance parameter <code>γ</code>. The new noise estimate is computed as:
    </p>
    <blockquote>
        <code>ϵ = ϵ<sub>u</sub> + γ(ϵ<sub>c</sub> − ϵ<sub>u</sub>)</code>
    </blockquote>
    <p>
        By setting <code>γ > 1</code>, we achieve significantly higher-quality images at the expense of diversity. For <code>γ = 0</code>, the model generates unconditional results, and for <code>γ = 1</code>, it creates conditional results. The images below demonstrate the improvement in quality using CFG with <code>γ = 7</code>.
    </p>
    <div class="image-container">
        <img src="images5/part1_6.png" alt="Images generated using CFG with γ=7">
        <div class="caption">Images generated using Classifier-Free Guidance (γ=7)</div>
    </div>


  

        <h2>Part 7. Image-to-Image Translation</h2>
    <p>
        In this part, we explored the SDEdit algorithm to make creative edits to an image. By adding noise to a real image and denoising it using the diffusion model, we force the noisy image back onto the manifold of natural images. The extent of the edit depends on the noise level—higher noise levels lead to larger edits, while lower noise levels retain more of the original structure.
    </p>
    <p>
        Using the prompt <code>"a high quality photo"</code>, we applied this technique to the original test image at noise levels <code>[1, 3, 5, 7, 10, 20]</code>. The results demonstrate how the image transitions from noisy to more refined, with creative edits made by the model.
    </p>
    <h3>Results: Original Test Image</h3>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/part_1_711.png" alt="Edit at noise level 1">
            <div class="caption">First noise levels</div>
        </div>
        <div class="image-container">
            <img src="images5/part_1_712.png" alt="Edit at noise level 3">
            <div class="caption">Last noise levels</div>
        </div>
        
    </div>
    
    <h3>Results: Custom Test Images: Muhammed Ali</h3>
       <p>
        We repeated the process on two additional test images using the same noise levels. Below are the results for one of the custom images.
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/ali_1.png" alt="Edit at noise level 7">
            <div class="caption">Early noise levels</div>
        </div>
        <div class="image-container">
            <img src="images5/ali_2.png" alt="Edit at noise level 10">
            <div class="caption">Last noise levels</div>
        </div>
        <div class="image-container">
            <img src="images5/ali.webp" alt="Edit at noise level 20">
            <div class="caption">Original image</div>
        </div>
    </div>

  
 <div class="image-row">
    <div class="image-container">
        <img src="images5/goldengate_1.png" alt="Custom Test Image Edits">
        <div class="caption">Early noise levels</div>
    </div>
    <div class="image-container">
        <img src="images5/goldengate_2.png" alt="Custom Test Image Edits">
        <div class="caption">Last noise levels</div>
    </div>
    <div class="image-container">
        <img src="images5/goldengate.jpg" alt="Custom Test Image Edits">
        <div class="caption">Original image image</div>
    </div>
    </div>

      <h2>Part 7.1 Image-to-Image Translation for Hand-Drawn Images</h2>
    <p>
        In this part, we apply the same image-to-image translation technique but use hand-drawn images as input. Below is one hand-drawn image from the web and two images drawn by me.
    </p>

    <h3>Results: Web Image</h3>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/web_house.jpg" alt="Original Web Image">
            <div class="caption">Original Image</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_7_web.png" alt="Edited Web Image">
            <div class="caption">Edit at Different Noise Levels</div>
        </div>
    </div>

    <h3>Results: Custom Test Images - Hand-Drawn</h3>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/Snoopy.jpg" alt="Original Drawing of Snoopy">
            <div class="caption">Original Drawing of Snoopy</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_7_snoopy.png" alt="Edited Drawing of Snoopy">
            <div class="caption">Edit at Different Noise Levels</div>
        </div>
    </div>

    <div class="image-row">
        <div class="image-container">
            <img src="images5/One_love.jpg" alt="Original Hand-Drawn Image">
            <div class="caption">Original Drawing</div>
        </div>
        <div class="image-container">
            <img src="images5/part1_7_rut.png" alt="Edited Hand-Drawn Image">
            <div class="caption">Edit at Different Noise Levels</div>
        </div>
    </div>

        <h2>Part 7.2 Inpainting</h2>
    <p>
        In this section, we explore inpainting by following a method inspired by the RePaint paper. Given an image (<code>x<sub>orig</sub></code>) and a binary mask (<code>m</code>), we create a new image that preserves the original content where the mask is 0 and introduces new content where the mask is 1.
    </p>
    <p>
        To achieve this, we use the diffusion denoising loop with a small modification. At each denoising step, after obtaining <code>x<sub>t</sub></code>, we force it to retain the original pixels where <code>m</code> is 0, effectively leaving the masked areas intact. The process is defined as:
    </p>
    <blockquote>
        <code>x<sub>t</sub> ← m * x<sub>t</sub> + (1 − m) * forward(x<sub>orig</sub>, t)</code>
    </blockquote>
    <p>
        By iteratively applying this approach, the diffusion model fills in the masked area with new content while preserving the rest of the image. We applied this technique to inpaint the top of the Campanile using a custom mask.
    </p>
    
    <h3>Results: Inpainting the Campanile</h3>
    <div class="image-row">
       
        <div class="image-container">
            <img src="images5/part_1_7_mask.png" alt="Inpainting Mask for Campanile">
            <div class="caption">Stages</div>
        </div>
        <div class="image-container">
            <img src="images5/part_1_7_inpainted1.png" alt="Inpainted Image of the Campanile">
            <div class="caption">Inpainted Image of the Campanile</div>
        </div>
    </div>

    <h3>Results: Custom Inpainting on Two Additional Images</h3>
    <p>
        We further experimented with inpainting on two custom images, using different masks to replace selected areas of each image.
    </p>
    <div class="image-row">
        <div class="image-container">
            <img src="images5/eiffeltower.jpg" alt="Inpainting Mask for Custom Image 2">
            <div class="caption">Original Image </div>
        </div>
        
        <div class="image-container">
            <img src="images5/part_1_7_altered_eiffell.png" alt="Inpainting Mask for Custom Image 2">
            <div class="caption">Inpainted Image </div>
        </div>
    </div>
    
    <div class="image-row">
        
        <div class="image-container">
            <img src="images5/eye_mask.png" alt="Inpainting Mask for Custom Image 2">
            <div class="caption">Stages</div>
        </div>
        <div class="image-container">
            <img src="images5/part_1_7_altered_eye.png" alt="Inpainted Custom Image 2">
            <div class="caption">Inpainted Image </div>
        </div>
    </div>


      <footer>
        <p>© 2024 Kalle's Portfolio | Project 5: Diffusion Models</p>
        <p>Contact: <a href="mailto:kj00@berkeley.edu">kj00@berkeley.edu</a></p>
    </footer>
</body>
</html>
