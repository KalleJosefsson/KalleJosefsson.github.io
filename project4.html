<!DOCTYPE html>
<html lang="en">https://github.com/KalleJosefsson/KalleJosefsson.github.io/blob/main/project4.html
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 4: Mosaics</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 50px;
        }
        h1 {
            font-size: 2.5em;
            color: #4CAF50;
        }
        h2, h3, h4, h5, h6 {
            color: #4CAF50;
            margin-top: 40px;
        }
        p {
            font-size: 1.2em;
            line-height: 1.6em;
        }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            margin: 20px 0;
        }
        section {
            margin-bottom: 40px;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            font-size: 0.8em;
            color: #777;
        }
        .screenshot {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }
        .image-grid {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            justify-content: center;
            margin-top: 20px;
        }
        .image-pair {
            flex: 1;
            min-width: 300px;
            text-align: center;
        }
        .image-pair img {
            margin-bottom: 10px;
            border-radius: 10px;
        }
        .caption {
            font-style: italic;
        }
        .equation-container {
            background-color: white;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
        }

        .image-grid {
        display: flex;
        justify-content: space-around;
        margin-bottom: 20px;
    }

    .image-pair img {
        max-width: 100%;
        height: auto;
        border-radius: 10px;
    }

    /* Make the smaller image smaller */
    .smaller-image .image-pair img {
        width: 60%;  /* Adjust this to control the size */
        margin: 0 auto;
    }

    .caption {
        text-align: center;
        font-style: italic;
    }
    </style>
</head>
<body>
    <!-- Main Header -->
    <header>
        <h1>Project 4: Mosaics</h1>
    </header>

    <p>
        In order to create mosaics, we need to go over some theory, which is done below step for step:
    </p>

    <div class="equation-container">
        <h2>1. Homography Transformation</h2>
        <p>Points \( p = (x, y) \) in one image are mapped to points \( p' = (x', y') \) in another image:</p>
        <p>
            \[
            s \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} =
            \mathbf{H} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}
            \]
        </p>
        <p>where \( \mathbf{H} \) is the \( 3 \times 3 \) homography matrix and \( s \) is a scale factor.</p>
    </div>

    <div class="equation-container">
        <h2>2. Structure of Homography Matrix (note the scaling factor h_{33} = 1)\( \mathbf{H} \)</h2>
        <p>
            \[
            \mathbf{H} =
            \begin{bmatrix}
            h_{11} & h_{12} & h_{13} \\
            h_{21} & h_{22} & h_{23} \\
            h_{31} & h_{32} & 1
            \end{bmatrix}
            \]
        </p>
    </div>

    <div class="equation-container">
        <h2>3. Linear System for Estimating \( \mathbf{H} \)</h2>
        <p>Given corresponding points \( (x, y) \) and \( (x', y') \), the following equations are formed:</p>
        <p>
            \[
            \begin{aligned}
            x' &= \frac{h_{11}x + h_{12}y + h_{13}}{h_{31}x + h_{32}y + 1} \\
            y' &= \frac{h_{21}x + h_{22}y + h_{23}}{h_{31}x + h_{32}y + 1}
            \end{aligned}
            \]
        </p>
    </div>

    <div class="equation-container">
        <h2>4. Matrix Formulation for Multiple Points</h2>
        <p>The system can be linearized as:</p>
        <p>
            \[
            \mathbf{A} \mathbf{h} = 0
            \]
        </p>
        <p>where \( \mathbf{A} \) is the design matrix and \( \mathbf{h} \) is a vector of the elements of \( \mathbf{H} \).</p>

        <p>The design matrix \( \mathbf{A} \) for a set of corresponding points \( (x_1, y_1) \) and \( (x_1', y_1') \) is constructed as follows:</p>
        <p>
            \[
            \mathbf{A} = \begin{bmatrix}
            x_1 & y_1 & 1 & 0 & 0 & 0 & -x_1 x_1' & -y_1 x_1' \\
            0 & 0 & 0 & x_1 & y_1 & 1 & -x_1 y_1' & -y_1 y_1'
            \end{bmatrix}
            \]
        </p>
        <p>
            Each pair of corresponding points contributes two rows to the matrix \( \mathbf{A} \). For additional point correspondences, the same pattern repeats, adding new rows to \( \mathbf{A} \). The system is then solved for the vector \( \mathbf{h} \), which contains the elements \( h_{11}, h_{12}, h_{13}, h_{21}, h_{22}, h_{23}, h_{31}, h_{32} \).
        </p>
    </div>

    <div class="equation-container">
        <h2>5. Using More Points and Least Squares</h2>
        <p>
            Although four points are sufficient to estimate the homography matrix \( \mathbf{H} \), using more than four points improves accuracy. By including additional point correspondences, we create an overdetermined system, which can be solved using the least squares method. The least squares approach minimizes the sum of squared errors between the predicted and actual point correspondences, yielding a more robust estimate of \( \mathbf{H} \) that accounts for noise and small variations in the data.
        </p>
    </div>

    <div class="equation-container">
    <h2>6. Image Warping</h2>
    <p>
        Image warping is a key step in creating mosaics, where the goal is to transform one image to align with another using the homography matrix \( \mathbf{H} \). Once we have calculated the homography matrix, we apply it to map the points in the source image to the corresponding points in the target image.
    </p>
    <p>
        To warp an image, for each pixel \( (x', y') \) in the target image, we calculate the corresponding point \( (x, y) \) in the source image using the inverse of the homography transformation:
    </p>
    <p>
        \[
        s \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} =
        \mathbf{H}^{-1} \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix}
        \]
    </p>
    <p>
        Here, \( \mathbf{H}^{-1} \) is the inverse of the homography matrix, and the resulting point \( (x, y) \) is mapped back into the original image.
    </p>

    <p>
        Since the result of this transformation may not lie exactly on an integer pixel, interpolation is used to estimate the pixel intensity at fractional coordinates. Common interpolation methods include nearest-neighbor, bilinear, or bicubic interpolation. This ensures that the warped image retains high-quality visual features.
    </p>

    <p>
        The warping process is repeated for every pixel in the target image, transforming the entire source image to align with the desired view. This enables smooth blending and accurate alignment between images in the final mosaic.
    </p>
</div>

<div class="equation-container">
    <h2>7. Bounding Box of the Warped Image</h2>
    <p>
        After warping an image using the homography matrix \( \mathbf{H} \), the transformed image might not align neatly within the original image boundaries. To ensure that the entire warped image is visible, we compute the bounding box of the transformed image.
    </p>
    <p>
        The bounding box is determined by applying the homography transformation to the four corners of the source image. The corners of an image at coordinates \( (0, 0), (w, 0), (w, h), (0, h) \) (where \( w \) and \( h \) are the width and height of the source image, respectively) are warped using the homography matrix:
    </p>
    <p>
        \[
        \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} = \mathbf{H} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}
        \]
    </p>
    <p>
        Once the new positions of the four corners are calculated, the minimum and maximum \( x' \) and \( y' \) values provide the extents of the bounding box. This defines the size of the canvas required to display the entire warped image without cropping.
    </p>
    <p>
        It is important to adjust the image translation so that the warped image fits within the computed bounding box. 
    </p>
</div>


<div class="equation-container">
    <h2>8. Image Stitching Using Two Corresponding Points and alpha blending</h2>
<p>
    The stitching process begins by identifying two pairs of corresponding points, \( p_1 \) and \( p_2 \) in the first image, and their corresponding points \( p_1' \) and \( p_2' \) in the second image. These points are used to calculate the transformation needed to align the images. Specifically, we ensure that both \( p_1 \) aligns with \( p_1' \), and \( p_2 \) aligns with \( p_2' \), which enables us to precisely position the images for stitching.
</p>

<p>
    The required transformation to align the two images is primarily a translation, as we use the distance between the corresponding points to shift one image relative to the other. Although this translation is mostly in the x-direction (horizontal), slight vertical adjustments in the y-direction may be necessary due to differences in the cameraâ€™s center of projection (COP). Once the translation is applied, the images are aligned, and we can perform alpha blending in the overlapping region to create a smooth transition between them.
</p>

<h3>Stitching Process Using Two Corresponding Points</h3>
<ol>
    <li>Identify two corresponding points \( p_1, p_2 \) in the first image and their corresponding points \( p_1', p_2' \) in the second image by warping the points.</li>
    <li>Compute the translation matrix \( T \) that moves \( p_1 \) in the first image to align with \( p_1' \) in the second image. This translation primarily occurs in the x-direction, though a slight y-translation may be applied to account for small vertical offsets.</li>
    <li>Apply the transformation \( T \) to shift the second image, aligning the two pairs of corresponding points with their counterparts in the first image.</li>
    <li>Perform alpha blending in the overlapping region. The blending weights are determined based on the distance from the center of each image, with influence decreasing as the distance increases. This results in a smooth transition between the two aligned images.</li>
    <li>Concatenate the non-overlapping parts of the images with the blended region to form the final mosaic.</li>
</ol>


  

   
</div>


    <div class="equation-container">
    <h2>9. Image Rectification</h2>
    <p>
        Image rectification is the process of transforming two or more images to align them onto a common plane. This technique is particularly useful when dealing with stereo images or overlapping images that need to be stitched together. The goal of rectification is to make corresponding points in the images appear at the same vertical position, which simplifies the stitching or matching process.
    </p>
    <p>
        Rectification involves calculating the homography transformations needed to warp both images so that their epipolar lines are aligned. Once the images are rectified, any point in one image will have a corresponding point along the same row in the second image. This ensures that when images are stitched together or matched, the alignment is accurate and seamless which is why we warp images to a cneter image.
    </p>
    <p>
        Below are examples of image rectification applied to two pairs of images. For each pair, we show the original images followed by the rectified versions. The rectified images demonstrate how the homography transformation has changed where the image is projecteed.
    </p>

    <h3>9.1 Pair 1: Original and Rectified Images</h3>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/book_front.jpg" alt="Original Image 1">
            <p class="caption">Figure 1: Original Image of book from the front</p>
        </div>
        <div class="image-pair">
            <img src="./images4/book_up.jpg" alt="Rectified Image 1">
            <p class="caption">Figure 2: Rectified Image seeing the book from above </p>
        </div>
    </div>
    
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/wb_left.jpg" alt="Original Image 2">
            <p class="caption">Figure 3: Original Image of Whiteboard from the left </p>
        </div>
        <div class="image-pair">
            <img src="./images4/wb_front.jpg" alt="Rectified Image 2">
            <p class="caption">Figure 4: Rectified Image seing the Whiteboard from the front </p>
        </div>
    </div>

   

    <p>
        These rectified images illustrate how the process transforms the original images, ensuring that they are aligned on the same plane. This alignment is crucial for performing tasks like image stitching or stereo matching, where corresponding points must appear at the same vertical location in both images.
    </p>
</div>

     <div class="equation-container">
    <h2>10. Creating the mosaics</h2>
    <p>
        Below are the three created mosaics which are created by following the above steps and then combining them together. I will show three examples the last two of them with alpha blending with weights being based on distance from image centers. 
        The first example I tried to just use a vertical mask with weights being changen linearly from 0-1 and 1-0 for respective images over the blending area. I thought this would work well
        since we are stitching the images horizontally but since images are of different size the artifacts could be found.
    </p>

   <h2>10.1 Creations of Mosaics</h2>
<h3>Ex: Originals and Mosaic (Vertical blend)</h3>
<div class="image-grid">
    <!-- First Row: 3 Images -->
    <div class="image-pair">
        <img src="./images4/a_left.jpg" alt="Original Image 1">
        <p class="caption">Left image of a group room at Moffitt</p>
    </div>
    <div class="image-pair">
        <img src="./images4/a_right.jpg" alt="Rectified Image 1">
        <p class="caption">Right image of a group room at Moffitt</p>
    </div>
    <div class="image-pair">
        <img src="./images4/filip_wared.jpg" alt="Original Image 2">
        <p class="caption">Warped left image</p>
    </div>
</div>

<!-- Smaller Image Below the First Row -->
<div class="image-grid smaller-image">
    <div class="image-pair">
        <img src="./images4/filip_mosaic.jpg" alt="Original Image 2">
        <p class="caption">Mosaic of a group room (Notice artifacts)</p>
    </div>
</div>

<h3>10.2 Ex 2: Originals and Mosaic (Distance to center based alpha blend)</h3>
<div class="image-grid">
    <!-- First Row: 3 Images -->
    <div class="image-pair">
        <img src="./images4/b_left.jpg" alt="Original Image 3">
        <p class="caption">Campus left side</p>
    </div>
    <div class="image-pair">
        <img src="./images4/b_middle.jpg" alt="Rectified Image 3">
        <p class="caption">Campus right side</p>
    </div>
    <div class="image-pair">
        <img src="./images4/b_warped_to_the_right.jpg" alt="Original Image 4">
        <p class="caption">Left warped to right</p>
    </div>
</div>

<!-- Smaller Image Below the First Row -->
<div class="image-grid smaller-image">
    <div class="image-pair">
        <img src="./images4/stitched_berkely.jpg" alt="Original Image 4">
        <p class="caption">Mosaic with alpha blend based on distance to centers (No artifacts)</p>
    </div>
</div>




<h3>10.3 Ex 3: Originals and Mosaic (Distance to center based alpha blend)</h3>
<div class="image-grid">
    <!-- First Row: 3 Images -->
    <div class="image-pair">
        <img src="./images4/c_left.jpg" alt="Original Image 5">
        <p class="caption">Moffitt Left</p>
    </div>
    <div class="image-pair">
        <img src="./images4/c_right.jpg" alt="Rectified Image 5">
        <p class="caption">Moffitt Right</p>
    </div>
    <div class="image-pair">
        <img src="./images4/c_warped.jpg" alt="Original Image 6">
        <p class="caption">Left warped</p>
    </div>
</div>

         <!-- Smaller Image Below the First Row -->
<div class="image-grid smaller-image">
    <div class="image-pair">
        <img src="./images4/c_mosaic.jpg" alt="Original Image 4">
        <p class="caption">Mosaic with alpha blend based on distance to centers (No artifacts)</p>
    </div>
</div>





   

    <p>
        These mosaics are my results from 4A and I thought it was really cool that we could do this without any type of machine learning our new data. I can't stress enough how important
        it is to not alter the center of projection when taking the photos or not picking pixel perfect correspondences. I had to do this in order to get good results I noticed after a lot
        of frustration. I look forward to doing this without manually annotating the points :D
    </p>
</div>


 <div class="equation-container">
    <h2>11. Harris Corners</h2>
    <p>
        Harris corner detection is a fundamental technique for identifying corner-like features in an image. Corners are regions where intensity changes significantly in multiple directions, making them ideal for tracking and matching in computer vision tasks. The Harris corner detector computes the gradient of the image in both x and y directions, forming a structure tensor at each pixel. This tensor captures how much the intensity changes in each direction, allowing us to compute a corner response function to detect corners.
    </p>
    <p>
        Mathematically, the corner response \( R \) is defined as:
    </p>
    <p>
        \[
        R = \det(\mathbf{M}) - k \cdot (\text{trace}(\mathbf{M}))^2
        \]
    </p>
    <p>
        Here, \( \mathbf{M} \) is the structure tensor formed from the image gradients, and \( k \) is a sensitivity factor.
    </p>
    <p>
        Below is an example of Harris corner detection applied to an image.
    </p>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/all_harris.jpg" alt="Harris Corners">
            <p class="caption">All Harris Corners detected in an image.</p>
        </div>
    </div>
</div>

<div class="equation-container">
    <h2>12. Adaptive Non-Maximal Suppression</h2>
    <p>
        After detecting corners, not all of them are equally important or distinctive. To reduce redundancy, we apply Adaptive Non-Maximal Suppression (ANMS). ANMS helps retain only the most salient features by selecting corners that are stronger than their neighbors within a specified radius. This ensures an even distribution of keypoints across the image, which improves the robustness of matching and other subsequent tasks.
    </p>
    <p>
        The suppression radius for each corner is computed based on the strength of its response and the distance to stronger nearby corners, ensuring that only distinctive and well-separated keypoints are retained.
    </p>
    <p>
        Below is an image showing the result of applying ANMS to a set of detected Harris corners.
    </p>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/Top_corners.png" alt="ANMS Applied">
            <p class="caption">Corners after applying Adaptive Non-Maximal Suppression.</p>
        </div>
    </div>
</div>

<div class="equation-container">
    <h2>13. Feature Descriptor Extraction</h2>
    <p>
        Once we have detected keypoints, the next step is to extract feature descriptors. For each keypoint, we extract an axis-aligned 8x8 patch of pixels around it. However, instead of taking this patch directly, we sample it from a larger 40x40 window. Sampling from a larger window allows us to first gaussian blur the patch then downscale it to 8x8, which creates a descriptor that is more robust to small changes in scale, orientation but also differences in lightintenisties.
    </p>
    <p>
        It's crucial to bias and gain-normalize the descriptor. Bias normalization ensures that the descriptor has zero mean, removing the effect of overall intensity changes, while gain normalization scales the descriptor so that it has unit variance, ensuring that the descriptor is not dominated by contrast variations. By doing all of the above we create a higher chance of getting matches which are correct even though
        there is some light intensity change or orientation change.
    </p>
    <p>
        Below are two images of normalized 8x8 patches for two images, note these are not the pairs but the strongest harris corners. Notice that they have a lot of white and black in them due to clipping of the values. Since we made the patches zero mean they will have negative values which will come out as black when shown. 
    </p>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/features.png" alt="Raw Patch">
            <p class="caption">64 first features from first image</p>
        </div>
        <div class="image-pair">
            <img src="./images4/feature1.png" alt="Normalized Patch">
            <p class="caption">64 first features from second image</p>
        </div>
    </div>
</div>

<div class="equation-container">
    <h2>14. Feature Matching</h2>
    <p>
        After extracting descriptors, the next step is to match features between two images. To do this, we compare each descriptor in the first image with every descriptor in the second image, identifying the pairs of descriptors that are most similar. The similarity between descriptors is usually measured using the Euclidean distance.
    </p>
    <p>
        To ensure robust matching, we use Loweâ€™s ratio test. For each descriptor in the first image, we find its two nearest neighbors in the second image. We accept the match only if the distance to the closest neighbor is significantly smaller than the distance to the second closest neighbor, as this indicates that the match is unambiguous. The threshold ratio is typically set around 0.8.
    </p>
    <p>
        Below is an image showing matched features between two images after applying Lowe's ratio test, notice that many of the matches are correct but there are still some which would affect the homography negatively. In the next section I explain how we get rid of these outliers.
    </p>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/Pre_ransac1.png" alt="Feature Matching">
            <p class="caption"> Matched features after applying Lowe's ratio test.</p>
        </div>
    </div>
</div>

<div class="equation-container">
    <h2>15. RANSAC for Outlier Removal</h2>
    <p>
        Even with the best matching techniques, there may still be incorrect matches, or outliers, that could distort the final result. To remove these outliers, we use RANSAC (Random Sample Consensus). RANSAC is an iterative method that repeatedly selects a random subset of four matches, computes a homography based on that subset, and then tests how well the homography aligns with the rest of the matches.
    </p>
    <p>
        Matches that do not fit well with the computed homography are considered outliers and matches which are within a 1 pixel radiues are considered correct and are considered inliers. We do this process a number of times and record the which are inliers and the amount of them. The largest list of inliers is then used to compute the final homography matrix as in part A, i.e with more than 4 points and we
        take the least square in order to get a robust and well working result.
    </p>
    <p>
        Below is an image showing feature matches after RANSAC. Compare it with the above and see that now we do not have any outliers which will result in a correct Homography matrix.
    </p>
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/Ransac_corr1.png" alt="Before RANSAC">
            <p class="caption"> Feature matches after RANSAC.</p>
        </div>
       
    </div>
</div>

    <div class="equation-container">
    <h2>16. Results</h2>
    <p>
        Below are the results of creating auto-mosaics. In each row, the first two images are the input images used to generate the mosaic, and the third image shows the final mosaic. The process includes detecting keypoints, extracting descriptors, matching features, and applying homography to stitch the images together with a nice alpha blend.
    </p>

    <!-- First row of images -->
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/b_left.jpg" alt="Input Image 1 - A">
            <p class="caption">Input Image 1 (Left).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/b_middle.jpg" alt="Input Image 1 - B">
            <p class="caption"> Input Image 1 (Right).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/auto_mosaic_b.jpg" alt="Resulting Mosaic 1">
            <p class="caption"> Resulting Mosaic 1.</p>
        </div>
    </div>

    <!-- Second row of images -->
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/e_left.jpg" alt="Input Image 2 - A">
            <p class="caption"> Input Image 2 (Left).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/e_right.jpg" alt="Input Image 2 - B">
            <p class="caption"> Input Image 2 (Right).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/auto_mosaic_e.jpg" alt="Resulting Mosaic 2">
            <p class="caption"> Resulting Mosaic 2.</p>
        </div>
    </div>

    <!-- Third row of images -->
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/g_left.jpg" alt="Input Image 3 - A">
            <p class="caption">Input Image 3 (Left).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/g_right.jpg" alt="Input Image 3 - B">
            <p class="caption">Input Image 3 (Right).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/auto_mosaic_g.jpg" alt="Resulting Mosaic 3">
            <p class="caption">Resulting Mosaic 3.</p>
        </div>
    </div>

         <!-- Third row of images -->
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/f_left.jpg" alt="Input Image 3 - A">
            <p class="caption">Input Image 4 (Left).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/f_right.jpg" alt="Input Image 3 - B">
            <p class="caption">Input Image 4 (Right).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/auto_mosaic_f.jpg" alt="Resulting Mosaic 3">
            <p class="caption">Resulting Mosaic 4.</p>
        </div>

           <!-- Third row of images -->
    <div class="image-grid">
        <div class="image-pair">
            <img src="./images4/b_left.jpg" alt="Input Image 3 - A">
            <p class="caption">Input Image 5 (Left).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/b_right.jpg" alt="Input Image 3 - B">
            <p class="caption">Input Image 5 (Right).</p>
        </div>
        <div class="image-pair">
            <img src="./images4/auto_mosaic_e_bigger.jpg" alt="Resulting Mosaic 3">
            <p class="caption"> Resulting Mosaic 5.</p>
        </div>
    </div>

    <p>
        These results demonstrate the effectiveness of the auto-mosaic generation process, showing accurate alignment and blending of images to create smooth and continuous mosaics. The last image show a mosaic with much less overlap than the others
        which I thought would be fun to try and it worked well. I also tried taking the images a bit more sloppy without a hyperfixed center of projection to see the results this can be seen in the second last mosaic. Notice how it is a little bit blurry.
        Probably due to the fact that a simple translation is not good enough for alignment when the COP is changed between the images. All and all a very fun project, still amazed how simple these operations are and yet they produce so cool results. My final function
        just took two images no other adjustable paramaters and spat out a mosaic which was alos pretty cool.
    </p>
</div>






    <!-- Footer Section -->
    <footer>
        <p>Â© 2024 Kalle's Portfolio | Project 4: Mosaics</p>
        <p>Contact: <a href="mailto:kj00@berkeley.edu">kj00@berkeley.edu</a></p>
    </footer>
</body>
</html>
