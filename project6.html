
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> Final Project:NeRFs</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 50px;
        }
        h1 {
            font-size: 2.5em;
            color: #4CAF50;
        }
        h2, h3 {
            color: #4CAF50;
            margin-top: 40px;
        }
        p {
            font-size: 1.2em;
            line-height: 1.6em;
        }
        .image-row {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .image-container {
            text-align: center;
        }
        .image-container img {
            height: 200px; /* Set fixed height for all images */
            width: auto; /* Automatically adjust width to keep aspect ratio */
            border-radius: 10px;
        }
        .caption {
            margin-top: 10px;
            font-size: 14px;
            font-style: italic;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            font-size: 0.8em;
            color: #777;
        }
    </style>
</head>
<body>
    <header>
        <h1>Final Project: NeRFs</h1>
    </header>


    <h2>
        Part 1. 2D NeRFs
    </h2>

    <p>
        For the first we are supposed to fit a Neural Field to a an image. This is done by creating a Multi Layer Perecptron with Sinusoidal Positional Encoding. The architecture of the 
        MLP is presented below.
    </p>
    <div class="image-container">
            <img src="images6/1arc.jpg" alt="Denoising begins">
            <div class="caption">MLP architecture for Part 1</div>
        </div>
    <p>
        As you can see in the image above, the MLP has 3 layers with each having 256 hidden dimensions. All of the hidden layers uses the ReLU activation function and the final output layer using the Sigmoid activation function instead.
        Throughout part 1 I used the Adam optimizer function and Mean Squared Error as loss. For this part I tried out some different settings for the hyper parameters to see what worked best. Below you will se the results. 
    </p>
    <div class="image-container">
            <img src="images6/fox_1.png" alt="Denoising begins">
            <div class="caption">1. Number of Encoding Functions: 10 & Learningrate: 1e-3 & Number Iterations: 1000</div>
        </div>
    <div class="image-container">
            <img src="images6/fox_2.png" alt="Denoising begins">
            <div class="caption">2. Number of Encoding Functions: 21 & Learningrate: 1e-2 & Number Iterations: 1000</div>
        </div>
    <div class="image-container">
            <img src="images6/fox_final.png" alt="Denoising begins">
            <div class="caption">3. Number of Encoding Functions: 10 & Learningrate: 1e-2 & Number Iterations: 2000</div>
        </div>

    <p>
        Below I present the PSNR (Peak Signal to Noise Ratio) and Loss plots which we used as the metrics to evaluate the performance of our model.
    </p>

     <div class="image-row">
        <div class="image-container">
            <img src="images6/psnr_1.png" alt="Edit at noise level 1">
            <div class="caption">1.PSNR and Loss for Hyperparameters settings 1</div>
        </div>
        <div class="image-container">
            <img src="images6/psnr_2.png" alt="Edit at noise level 3">
            <div class="caption">PSNR and Loss for Hyperparameters settings 2</div>
        </div>
         <div class="image-container">
            <img src="images6/psnr_final.png" alt="Edit at noise level 3">
            <div class="caption">PSNR and Loss for Hyperparameters settings 3</div>
        </div>
        
    </div>

    <p>
        As we can see the model which has 10 positional encoding function works great for both learning rates and number of iterations. The model converges faster with a higher learning rate
        but utlimately reaches the same PSNR. However if we increase the number of positional encodings the model does not work well with reproducing the image, however the PSNR is still high.
    </p>

    <p>
        I also tested the model on an image of Ali the famous boxer. This image had fewer pixels than the image of the fox, making it easier for the model to get a good results.
        As we can see below the results are in fact better.
        
    </p>

 

    <div class="image-container">
            <img src="images6/ali_results.png" alt="Edit at noise level 1">
            <div class="caption">Number of Encoding Functions: 10 & Learningrate: 1e-2 & Number Iterations: 1000</div>
        </div>
    <div class="image-container">
            <img src="images6/ali_psnr.png" alt="Edit at noise level 3">
            <div class="caption">PSNR and Loss for Ali</div>
        </div>

    <p> Training took around 40 seconds using the GPU however since the model almost converged after 500 iterations we could decrease training time to around 20 seconds which I consider very fast</p>
     <h2>
        Part 2: 3D NeRFs
    </h2>
    

    <p>
        When constructing a neural radiance field for 3D, the process is similar to that for 2D but involves additional steps for ray sampling and volumetric rendering.
    </p>

    <p>
        To create the dataset, we start with a list of images, camera-to-world matrices, and the focal length, from which we compute the intrinsic matrix. For each ray, we randomly select a pixel from the available images and project it into 3D as a ray originating from the camera. This projected ray is then returned as the sampled ray.
    </p>

    <p>
        Using the sampled rays, we perform discrete steps along each ray, introducing a small perturbation to the sampling positions for added robustness. At these discrete points, we query the neural radiance field and aggregate the sampled values to generate the volumetric rendering.

Below is a visualization illustrating the ray sampling process from some of the cameras since all of them would be to much and give an unclear representation.
    </p>

    <div class="image-container">
            <img src="images6/3d_rays.png" alt="Edit at noise level 3">
            <div class="caption">Viser showing camera ray samples</div>
        </div>

    <p>
        When training the network I did it over 3000 iterations with a batchsize of 10000. Again we use the Adam optimizer and MSE as loss function. Now we have a larger MLP for which the architecture is
        presented in the image below.
    </p>

    <div class="image-container">
            <img src="images6/2arc.png" alt="Edit at noise level 3">
            <div class="caption">Network architecture for part 2</div>
        </div>
<p>
    Below is the progress during training.
</p>

    <div class="image-row">
        <div class="image-container">
            <img src="images6/iter100.jpg" alt="Edit at noise level 1">
            <div class="caption">Iteration 100</div>
        </div>
        <div class="image-container">
            <img src="images6/iter300.jpg" alt="Edit at noise level 3">
            <div class="caption">Iteration 300</div>
        </div>
         <div class="image-container">
            <img src="images6/iter800.jpg" alt="Edit at noise level 3">
            <div class="caption">Iteration 800</div>
        </div>
    </div>

    <div class="image-row">
        <div class="image-container">
            <img src="images6/iter1800.jpg" alt="Edit at noise level 1">
            <div class="caption">Iteration 1800</div>
        </div>
        <div class="image-container">
            <img src="images6/iter2400.jpg" alt="Edit at noise level 3">
            <div class="caption">Iteration 2400</div>
        </div>
        
    </div>
    
      <footer>
        <p>Â© 2024 Kalle's Portfolio | Final Project: NeRFs</p>
        <p>Contact: <a href="mailto:kj00@berkeley.edu">kj00@berkeley.edu</a></p>
    </footer>
</body>
</html>
